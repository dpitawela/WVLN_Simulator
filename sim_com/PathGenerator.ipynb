{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium\n",
    "# !pip install networkx\n",
    "# !pip install matplotlib\n",
    "# !pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from SimulatorCommunicator import setup, switchToIframe, scrollToTheBottom, updateURL, clickElement, takeScreenshot\n",
    "from PIL import Image\n",
    "\n",
    "import networkx as nx\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "import requests\n",
    "import io\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllClickables(driver):\n",
    "    elements = []\n",
    "\n",
    "    elements_a = driver.find_elements(By.TAG_NAME, 'a')\n",
    "    for element in elements_a:\n",
    "        if element.is_displayed() and element.is_enabled() and element.rect.__len__() != 0:  # excluding all the hidden links\n",
    "            # print(element.get_property('attributes')[0].items(), \"\\n\")\n",
    "\n",
    "            data = {}\n",
    "            data['x'] = element.rect['x']\n",
    "            data['y'] = element.rect['y']\n",
    "            data['width'] = element.rect['width']\n",
    "            data['height'] = element.rect['height']\n",
    "            data['outer_html'] = base64Encode(bytes(element.get_attribute('outerHTML'), \"utf-8\")) \n",
    "            data['href'] = element.get_dom_attribute('href')\n",
    "            data['href_full'] = element.get_attribute('href')\n",
    "            data['class'] = element.get_attribute('class')\n",
    "            data['text'] = list(itertools.chain(*[text.text.split('\\n') for text in element.find_elements(By.XPATH, './/div') if len(text.text) > 0]))\n",
    "            \n",
    "            # getting closer image(s) if available\n",
    "            imgs=element.find_elements(By.XPATH, \".//img\")\n",
    "            if len(imgs) > 0:\n",
    "                for i, img in enumerate(imgs):\n",
    "                    data['img_'+str(i)] = imgURL2B64(img.get_attribute('src'))\n",
    "\n",
    "            elements.append(data)\n",
    "    return elements\n",
    "\n",
    "# to get the URL of current page on iframe\n",
    "def getCurrntURLIFrame(driver):\n",
    "    url = driver.execute_script('return window.location.href')\n",
    "    url = url.replace('http://localhost:4200', \"\")\n",
    "    return url\n",
    "\n",
    "# download image from URL and convert to base64\n",
    "def imgURL2B64(imgURL):\n",
    "    # downloading image\n",
    "    img_data = requests.get(imgURL).content\n",
    "    # encoding\n",
    "    return base64Encode(img_data)\n",
    "\n",
    "# convert bytes string to b64 \n",
    "def base64Encode(data):\n",
    "    return base64.b64encode(data).decode(\"utf-8\")\n",
    "\n",
    "# show image from base64\n",
    "def imgFromB64(imgb64):\n",
    "    # reconstructing the image by decoding\n",
    "    img64dec = base64.b64decode(imgb64)\n",
    "    Image.open(io.BytesIO(img64dec)).show()\n",
    "\n",
    "# format data to store\n",
    "def formatData(chosenLink):\n",
    "    data = {}\n",
    "    data['y'] = chosenLink['y'] + chosenLink['height']\n",
    "    data['y_offset'] = 0\n",
    "\n",
    "    if (chosenLink['y'] + chosenLink['height']) > 720:\n",
    "        data['y'] = chosenLink['y'] - (chosenLink['y'] - 720 - chosenLink['height'])\n",
    "        data['y_offset'] = chosenLink['y'] + chosenLink['height'] - 720\n",
    "\n",
    "    # new attributes to the chosen link\n",
    "    chosenLink['type'] = \"click\"\n",
    "    chosenLink['y'] = data['y']\n",
    "    chosenLink['x_offset'] = 0\n",
    "    chosenLink['y_offset'] = data['y_offset']\n",
    "\n",
    "    return chosenLink\n",
    "\n",
    "# retrieves all the text on the page\n",
    "def getTextOnPage(driver):\n",
    "    divs = driver.find_elements(By.TAG_NAME, 'div')\n",
    "    return list(set(list(itertools.chain(*[[divText for divText in divs[i].text.split('\\n') if len(divText) > 0] for i in range(len(divs))]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PGEgaHJlZj0iY29sbGVjdGlvbnMvd29tZW5zLW5ldy1hcnJpdmFscy5odG1sIiBjbGFzcz0iYnV0dG9uCiAgICAgICAgICAgICAgICAgICAgICAgIGJ1dHRvbi1tZWRpdW0KICAgICAgICAgICAgICAgICAgICAgICAgYnV0dG9uLXdoaXRlCiAgICAgICAgICAgICAgICAgICAgICAgIHR4dC1zaXplLTIKICAgICAgICAgICAgICAgICAgICAgICAgdHh0LXRyYWNrZWQtdHdvLXBvaW50Ij4KICAgICAgICAgICAgICAgICBTaG9wIE5ldyBBcnJpdmFscwogICAgICAgICAgICAgIDwvYT4='"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"\"\"<a href=\"collections/womens-new-arrivals.html\" class=\"button\n",
    "                        button-medium\n",
    "                        button-white\n",
    "                        txt-size-2\n",
    "                        txt-tracked-two-point\">\n",
    "                 Shop New Arrivals\n",
    "              </a>\"\"\"\n",
    "base64.b64encode(bytes(x, \"utf-8\")).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks one against a list\n",
    "def isSimilar(query, reference, score):\n",
    "    points = 0\n",
    "    # relative url match\n",
    "    if(query[0]) == reference[0]:\n",
    "        points += 1\n",
    "\n",
    "    # absolute url match\n",
    "    if(query[1]) == reference[1]:\n",
    "        points += 1\n",
    "  \n",
    "    # class match  \n",
    "    if(query[2]) == reference[2]:\n",
    "        points += 1 \n",
    "\n",
    "    return points >= score\n",
    "\n",
    "# check one url\n",
    "def checkIfIn(query, urlList, score=2):\n",
    "    for url in urlList:\n",
    "        if isSimilar(query, url, score):\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [\n",
    "     ('#', 'index.html#', 'nav-link\\n                js-top-drawer-click')\n",
    "]\n",
    "\n",
    "l2 = [\n",
    "     ('collections/womens-new-arrivals.html', 'collections/womens-new-arrivals.html', 'topnav-mobile-link'),\n",
    "     ('collections/womens.html', 'collections/womens.html', 'topnav-mobile-link'), \n",
    "     ('collections/kids.html', 'collections/kids.html', 'topnav-mobile-link'),\n",
    "     ('collections/mens.html', 'collections/mens.html', 'topnav-mobile-link'),\n",
    "]\n",
    "\n",
    "l3 = [\n",
    "     ('collections/womens.html', 'collections/womens.html', 'topnav-mobile-link'),\n",
    "     ('collections/womens-new-arrivals.html', 'collections/womens-new-arrivals.html', 'topnav-mobile-link'),\n",
    "     ('collections/womens-socks.html', 'collections/womens-socks.html', 'topnav-mobile-link'),\n",
    "     ('collections/womens-tights-and-leggings.html', 'collections/womens-tights-and-leggings.html', 'topnav-mobile-link'),\n",
    "     ('collections/womens-clothing.html', 'collections/womens-clothing.html', 'topnav-mobile-link'),\n",
    "     ('collections/womens-bags.html', 'collections/womens-bags.html', 'topnav-mobile-link'),\n",
    "     ('collections/womens-sale.html', 'collections/womens-sale.html', 'topnav-mobile-link'),\n",
    "\n",
    "     ('collections/kids.html', 'collections/kids.html', 'topnav-mobile-link'),\n",
    "     ('collections/kids-new-arrivals.html', 'collections/kids-new-arrivals.html', 'topnav-mobile-link'),\n",
    "     ('collections/kids-socks.html', 'collections/kids-socks.html', 'topnav-mobile-link'),\n",
    "     ('collections/kids-tights-and-leggings.html', 'collections/kids-tights-and-leggings.html', 'topnav-mobile-link'),\n",
    "     ('collections/kids-sale.html', 'collections/kids-sale.html', 'topnav-mobile-link'),\n",
    "\n",
    "     ('collections/mens.html', 'collections/mens.html', 'topnav-mobile-link'),\n",
    "     ('collections/mens-new-arrivals-1.html', 'collections/mens-new-arrivals-1.html', 'topnav-mobile-link'),\n",
    "     ('collections/mens-socks.html', 'collections/mens-socks.html', 'topnav-mobile-link'),\n",
    "     ('collections/mens-sale.html', 'collections/mens-sale.html', 'topnav-mobile-link'),\n",
    "]\n",
    "\n",
    "eliminate = [\n",
    "     ('collections/mens.html', 'collections/mens.html', 'topnav-mobile-link'),\n",
    "     ('collections/womens-tights-and-leggings.html', 'collections/womens-tights-and-leggings.html', 'subnav-link\\n                        '),\n",
    "     ('collections/womens-bags.html', 'collections/womens-bags.html', 'subnav-link\\n                        '),\n",
    "     ('collections/womens-gift-card.html', 'collections/womens-gift-card.html', 'subnav-link\\n                        '),\n",
    "     ('collections/womens-sale.html', 'collections/womens-sale.html', 'subnav-link\\n                        '),\n",
    "     ('collections/womens-sporty-series.html', 'collections/womens-sporty-series.html', 'subnav-link\\n                        '),\n",
    "     ('collections/womens-conversational-crews.html', 'collections/womens-conversational-crews.html', 'subnav-link\\n                        '),\n",
    "     ('collections/womens-new-arrivals.html', 'collections/womens-new-arrivals.html', ''),\n",
    "     ('collections/kids-gift-card.html', 'collections/kids-gift-card.html', 'subnav-link\\n                        '),\n",
    "     ('collections/kids-sale.html', 'collections/kids-sale.html', 'subnav-link\\n                        '),\n",
    "     ('collections/kids-new-arrivals.html', 'collections/kids-new-arrivals.html', ''),\n",
    "     ('collections/mens-new-arrivals-1.html', 'collections/mens-new-arrivals-1.html', ''),\n",
    "     ('https://instagram.com/hanselfrombasel/', 'https://instagram.com/hanselfrombasel/', 'icon-instagram\\n                    footer-link\\n                    footer-link-social'),\n",
    "     ('https://www.facebook.com/HanselfromBasel', 'https://www.facebook.com/HanselfromBasel', 'icon-facebook\\n                    footer-link\\n                    footer-link-social'),\n",
    "     ('https://www.pinterest.com/hanselfrombasel/', 'https://www.pinterest.com/hanselfrombasel/', 'icon-pinterest\\n                    footer-link\\n                    footer-link-social'),\n",
    "\n",
    "     ('cart.html', 'cart.html', 'nav-link\\n                nav-link-mobile\\n                js-drawer-toggle'),\n",
    "]\n",
    "\n",
    "forceClick = [\n",
    "     ('collections/womens-new-arrivals.html', 'collections/womens-new-arrivals.html', 'button\\n                        button-medium\\n                        button-white\\n                        txt-size-2\\n                        txt-tracked-two-point'),\n",
    "]\n",
    "\n",
    "def l3Handle(l2):\n",
    "     if (\"womens\" in l2['href']):\n",
    "          return l3[:7]\n",
    "     elif(\"kids\" in l2['href']):\n",
    "          return l3[7:12]\n",
    "     elif(\"mens\" in l2['href']):\n",
    "          return l3[12:]\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # base code\n",
    "# base = \"http://localhost:4200/assets/crawled/hansel/hanselfrombasel.com/\"\n",
    "\n",
    "# def collectData():\n",
    "#     for stepitr in range(3,8): #3,16\n",
    "#         dpoint=1\n",
    "#         while dpoint <= 1: # no. of recordings needed from one seq. count\n",
    "#             driver = setup(True)\n",
    "#             switchToIframe(driver)\n",
    "\n",
    "#             menuState = 'non'\n",
    "#             visited = [] # to store visited links in one sequence\n",
    "#             data = {} # to collect data in one sequence\n",
    "#             data['url'] = \"assets/crawled/hansel/hanselfrombasel.com/index.html\"\n",
    "#             actions = [] # to store clicks\n",
    "\n",
    "#             try:\n",
    "#                 # steps = random.choice([x for x  in range(3,8)]) # generating number of steps\n",
    "#                 for step in range(stepitr): # going through steps in a single data point\n",
    "#                     scrollToTheBottom(driver)\n",
    "\n",
    "#                      # adding constraints to click a button\n",
    "#                     if dpoint <= 4 and step == 0:\n",
    "#                             clickables = [clickable for clickable in getAllClickables(driver) if checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), l1, 3)]\n",
    "#                     elif dpoint <= 8 and step == 0:\n",
    "#                             clickables = [clickable for clickable in getAllClickables(driver) if checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), forceClick, 3)]\n",
    "                    \n",
    "#                     else:\n",
    "#                         if menuState == 'non':\n",
    "#                         # eliminating unwanted urls\n",
    "#                             clickables = [clickable for clickable in getAllClickables(driver) if not checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), eliminate, 2)]\n",
    "#                         elif menuState == 'l1':\n",
    "#                             clickables = [clickable for clickable in getAllClickables(driver) if checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), l2)]\n",
    "#                         elif menuState == 'l2':\n",
    "#                             clickables = [clickable for clickable in getAllClickables(driver) if checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), l3Handle(actions[-1]))]\n",
    "\n",
    "#                     # eliminating already visited ones\n",
    "#                     clickables = [clickable for clickable in clickables if not checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), visited)]\n",
    "\n",
    "#                     # choosing a clickable randomly\n",
    "#                     chosenLink = random.choice(clickables[:])\n",
    "\n",
    "#                     if checkIfIn((chosenLink['href'], chosenLink['href_full'].replace(base,\"\"), chosenLink['class']), l1):\n",
    "#                         menuState = 'l1'\n",
    "#                     elif checkIfIn((chosenLink['href'], chosenLink['href_full'].replace(base,\"\"), chosenLink['class']), l2[1:]):\n",
    "#                         menuState = 'l2'\n",
    "#                     else:\n",
    "#                         menuState = 'non'\n",
    "\n",
    "#                     # adding to the visited list\n",
    "#                     visited.append((chosenLink['href'], chosenLink['href_full'].replace(base,\"\"), chosenLink['class']))\n",
    "\n",
    "#                     # print(chosenLink['href_full'])\n",
    "#                     clickElement(driver, chosenLink['x'], chosenLink['y'])\n",
    "#                     actions.append(formatData(chosenLink))\n",
    "                \n",
    "#                 data['actions'] = actions\n",
    "#                 # saving to a json file\n",
    "#                 fname = str(int(time.time())) + '_' + str(stepitr)\n",
    "#                 with open('data/R_' + fname + '.json', 'w') as f:\n",
    "#                     json.dump(data, f)\n",
    "                \n",
    "#                 dpoint+=1 # increasing the iteration number\n",
    "#                 print(fname, [action['href'] for action in actions])\n",
    "\n",
    "#                 # break\n",
    "#             except Exception as e:\n",
    "#                 pass\n",
    "#                 # print('\\033[91m', 'step_itr:', stepitr, 'dpoint:', dpoint)\n",
    "#                 # print(chosenLink['href_full'], '\\n')\n",
    "#                 # if actions.__len__() > 0:\n",
    "#                 #     print([action['href'] for action in actions])\n",
    "#                 # print('\\033[0m', \"-----------------------------------------------------\")\n",
    "\n",
    "# collectData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"http://localhost:4200/assets/crawled/hansel/hanselfrombasel.com/\"\n",
    "\n",
    "def collectData():\n",
    "    for stepitr in range(2, 3): #3,16\n",
    "        dpoint=1\n",
    "        while dpoint <= 1: # no. of recordings needed from one seq. count\n",
    "            driver = setup(True)\n",
    "            switchToIframe(driver)\n",
    "\n",
    "            menuState = 'non'\n",
    "            visited = [] # to store visited links in one sequence\n",
    "            data = {} # to collect data in one sequence\n",
    "            data['url'] = \"assets/crawled/hansel/hanselfrombasel.com/index.html\"\n",
    "            actions = [] # to store clicks\n",
    "\n",
    "            # try:\n",
    "            # steps = random.choice([x for x  in range(3,8)]) # generating number of steps\n",
    "            for step in range(stepitr): # going through steps in a single data point\n",
    "                print(\"lol\")\n",
    "                scrollToTheBottom(driver)\n",
    "\n",
    "                candidate_clickables = getAllClickables(driver)\n",
    "                # print(candidate_clickables)\n",
    "\n",
    "                    # adding constraints to click a button\n",
    "                if dpoint <= 4 and step == 0:\n",
    "                        clickables = [clickable for clickable in candidate_clickables if checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), l1, 3)]\n",
    "                elif dpoint <= 8 and step == 0:\n",
    "                        clickables = [clickable for clickable in candidate_clickables if checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), forceClick, 3)]\n",
    "                \n",
    "                else:\n",
    "                    if menuState == 'non':\n",
    "                    # eliminating unwanted urls\n",
    "                        clickables = [clickable for clickable in candidate_clickables if not checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), eliminate, 2)]\n",
    "                    elif menuState == 'l1':\n",
    "                        clickables = [clickable for clickable in candidate_clickables if checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), l2)]\n",
    "                    elif menuState == 'l2':\n",
    "                        clickables = [clickable for clickable in candidate_clickables if checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), l3Handle(actions[-1]))]\n",
    "            \n",
    "                # eliminating already visited ones\n",
    "                clickables = [clickable for clickable in clickables if not checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), visited)]\n",
    "\n",
    "                # choosing a clickable randomly\n",
    "                chosenLink = random.choice(clickables[:])\n",
    "                \n",
    "                # assigning the menu state\n",
    "                if checkIfIn((chosenLink['href'], chosenLink['href_full'].replace(base,\"\"), chosenLink['class']), l1):\n",
    "                    menuState = 'l1'\n",
    "                elif checkIfIn((chosenLink['href'], chosenLink['href_full'].replace(base,\"\"), chosenLink['class']), l2[1:]):\n",
    "                    menuState = 'l2'\n",
    "                else:\n",
    "                    menuState = 'non'\n",
    "                \n",
    "                # adding to the visited list\n",
    "                visited.append((chosenLink['href'], chosenLink['href_full'].replace(base,\"\"), chosenLink['class']))\n",
    "\n",
    "                # print(chosenLink['href_full'])\n",
    "                clickElement(driver, chosenLink['x'], chosenLink['y'])\n",
    "\n",
    "                actions.append({\n",
    "                    'clicked': formatData(chosenLink),\n",
    "                    'candidates': [formatData(clickable) for clickable in candidate_clickables],\n",
    "                    'screenshot': takeScreenshot(driver),\n",
    "                    'full_url': getCurrntURLIFrame(driver),\n",
    "                    'text': getTextOnPage(driver)\n",
    "                    })\n",
    "\n",
    "            data['actions'] = actions\n",
    "\n",
    "            # saving to a json file\n",
    "            fname = str(int(time.time())) + '_' + str(stepitr)\n",
    "            with open('data/R_' + fname + '.json', 'w') as f:\n",
    "                json.dump(data, f)\n",
    "            \n",
    "            dpoint+=1 # increasing the iteration number\n",
    "            # print(fname, [action['clicked']['href'] for action in actions])\n",
    "\n",
    "                # break\n",
    "            # except Exception as e:\n",
    "                # print(\"error\", e)\n",
    "                # print('\\033[91m', 'step_itr:', stepitr, 'dpoint:', dpoint)\n",
    "                # print(chosenLink['href_full'], '\\n')\n",
    "                # if actions.__len__() > 0:\n",
    "                #     print([action['href'] for action in actions])\n",
    "                # print('\\033[0m', \"-----------------------------------------------------\")\n",
    "# collectData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stockists',\n",
       " 'Queen Of Hearts Crew',\n",
       " 'Umbrella Short Crew',\n",
       " 'Bemberg Rib Short Crew',\n",
       " 'Trouser Crew',\n",
       " '$24 $16.80',\n",
       " 'Seltzer Short Crew',\n",
       " 'Kismet Crew',\n",
       " '$41',\n",
       " \"Men's\",\n",
       " 'Wilhelm Crew',\n",
       " 'LOADING MORE',\n",
       " 'ASSISTANCE',\n",
       " \"Women's New Arrivals\",\n",
       " 'ABOUT US',\n",
       " '$14',\n",
       " 'Half + Half Crew',\n",
       " 'Sustainability Rules Crew',\n",
       " 'Jane Crew',\n",
       " 'Wiggly Sheer Short Crew',\n",
       " 'Martina Pant',\n",
       " 'Anise Sheer Crew',\n",
       " '© Hansel from Basel 2022',\n",
       " 'Amalfi Crew',\n",
       " 'Lucid Crew',\n",
       " 'Swirl Crew',\n",
       " 'Fundamental Liner 2pr Pack',\n",
       " 'Rosie Crew',\n",
       " 'RESTOCKED',\n",
       " 'Size Guide',\n",
       " 'Penny Apron Dress',\n",
       " '$232',\n",
       " 'FREE SHIPPING ON US ORDERS $75+',\n",
       " 'Margaret Dress',\n",
       " '$43',\n",
       " 'Sci Fi Sporty Tall Crew',\n",
       " 'Conversational',\n",
       " '$36',\n",
       " '카드에 연결된 주소입니다',\n",
       " 'Ulla Crew',\n",
       " 'Press',\n",
       " 'Cecilia Crew',\n",
       " 'SALE',\n",
       " 'Utility Slub Crew',\n",
       " 'Baby Strawberry Sheer Short Crew',\n",
       " 'Collegiate Hearts Crew',\n",
       " '$21 $16.80',\n",
       " 'Phys Ed Crew',\n",
       " 'Bandana Patched Crew',\n",
       " '$23',\n",
       " 'ONLY A FEW LEFT!',\n",
       " 'Granny Crew',\n",
       " 'Facebook',\n",
       " 'Rainbow Brite Crew',\n",
       " 'MORE COLORS',\n",
       " 'Ethel Crew',\n",
       " 'Nautical Stripe Crew',\n",
       " 'Hippy Dippy Flowers Crew',\n",
       " 'Toons Short Crew',\n",
       " 'Instagram',\n",
       " 'Sun Daisy Crew',\n",
       " 'Dapple Crew',\n",
       " 'Care Instructions',\n",
       " '$32',\n",
       " 'Sweet Tie Dye Crew',\n",
       " 'Leon Short Crew',\n",
       " 'Privacy Policy',\n",
       " 'Bags',\n",
       " 'Mariposa Sheer Crew',\n",
       " 'Waldo Wool Boot Crew',\n",
       " 'Buffy Crew',\n",
       " '$14 Sold Out',\n",
       " 'Tights and Leggings',\n",
       " 'Contact Us',\n",
       " 'Sloane Dress',\n",
       " 'Taffy Short Crew',\n",
       " '$26 $19.50',\n",
       " 'Kinu Silk Short Crew',\n",
       " 'Good Vibes Stripe Crew',\n",
       " '$21 $14.70',\n",
       " 'Shipping Policy',\n",
       " 'Hoodie Wool Crew',\n",
       " 'Rainbow Brite Sheer Crew',\n",
       " '$223',\n",
       " '$12',\n",
       " 'Apéritif Crew',\n",
       " 'Rib Cashmere Knee Hi',\n",
       " 'Amarena Crew',\n",
       " '$205',\n",
       " 'Hodge Podge Crew',\n",
       " 'Cozy Cloud Wool Crew',\n",
       " \"Men's New Arrivals\",\n",
       " 'Wholesale',\n",
       " 'Lila Dress',\n",
       " 'Mood Short Crew',\n",
       " 'SHOP NOW',\n",
       " '$28',\n",
       " 'Pile Crew',\n",
       " '$196',\n",
       " '$18',\n",
       " '$35',\n",
       " 'Jolly Sheer Crew',\n",
       " 'Do Not Sell My Personal Information',\n",
       " 'Sci Fi Sporty Short Crew',\n",
       " 'Pop Sheer Short Crew',\n",
       " 'Sporty',\n",
       " '$161',\n",
       " '$150',\n",
       " 'Italia Cashmere Cozy Rib Crew',\n",
       " 'Fruit Stand Crew',\n",
       " 'Moo Sheer Short Crew',\n",
       " '$46 $32.20',\n",
       " 'Rie Crew',\n",
       " '$163',\n",
       " '$57',\n",
       " '$20',\n",
       " 'Group Copymenu Created With Sketch.',\n",
       " 'Cool To Recycle Short Crew',\n",
       " 'Trouser Wool Crew',\n",
       " 'Bougainvillea Crew',\n",
       " '$21',\n",
       " 'Pinterest',\n",
       " 'Gift Card',\n",
       " 'Sunshine Liner 2pr Pack',\n",
       " 'HFB EXCLUSIVE',\n",
       " '$30',\n",
       " 'Love Mother Earth Crew',\n",
       " 'FOLLOW US',\n",
       " 'Little Cherries All Over Crew',\n",
       " '$26',\n",
       " 'Flora And Fauna Crew',\n",
       " 'Tigger Liner 2pr Pack',\n",
       " 'Leona Dress',\n",
       " 'Laura Crew',\n",
       " 'Scout Dress',\n",
       " '$17',\n",
       " 'Corbusier Crew',\n",
       " 'Courtside Short Crew',\n",
       " 'Cutout Short Crew',\n",
       " 'Peace Sheer Crew',\n",
       " 'Asha Jumpsuit',\n",
       " 'Love Cashmere Crew',\n",
       " \"Kid's New Arrivals\",\n",
       " 'Saute Short Crew',\n",
       " 'Forage Short Crew',\n",
       " 'Martha Crew',\n",
       " 'Our Story',\n",
       " 'Tonal Dapple Crew',\n",
       " 'Quinn Top',\n",
       " 'Our SS22 collection is composed of an abundance of florals, nostalgia of bygone eras, and kaleidoscopic configurations. Imagine the way the house of a kooky Aunt with endless half-finished passion projects might look. A little bit of this and a little bit of that and voila, HFB’s thoughtful and playful SS22 collection comes to shape! Revel in the unexpected this season and sport a variety of lightweight legwear and linen clothing with self-assurance!',\n",
       " 'Quilted Crew',\n",
       " 'INQUIRIES',\n",
       " 'Ping Pong Sporty Crew',\n",
       " 'Promotion Details',\n",
       " 'Argyle Wool Sporty Crew',\n",
       " '$173',\n",
       " 'FUNDAMENTALS',\n",
       " 'Matilija Sheer Short Crew',\n",
       " 'Returns + Exchanges']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = setup(False)\n",
    "switchToIframe(driver)\n",
    "getTextOnPage(driver)\n",
    "\n",
    "# x = getAllClickables(driver)\n",
    "# [(click['href'], click['href_full'].replace(base,\"\"), click['class']) for click in getAllClickables(driver)]\n",
    "\n",
    "# data = {\n",
    "#     'href':'assets/crawled/hansel/hanselfrombasel.com/index.html',\n",
    "#     'href_full':'assets/crawled/hansel/hanselfrombasel.com/index.html',\n",
    "#     'x': 0,\n",
    "#     'y': 0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectData(n_data):\n",
    "    driver = setup()\n",
    "    switchToIframe(driver)\n",
    "\n",
    "    for i in range(n_data):\n",
    "        # scrollToTheBottom(driver)\n",
    "        # clickables = getAllClickables(driver)\n",
    "        # chosenLink = random.choice(clickables[10:])\n",
    "        # print(chosenLink)\n",
    "\n",
    "        clickElement(driver, 414, 3000)\n",
    "        break\n",
    "\n",
    "        \n",
    "\n",
    "# collectData(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('wvln')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "5262f72f792da6885bb3d262717436bebfd49eeb6fd743e7744cb17ed52f3a82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
