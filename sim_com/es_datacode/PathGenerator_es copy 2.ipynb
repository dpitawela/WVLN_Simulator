{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from SimulatorCommunicator import setup, switchToIframe, scrollToTheBottom, updateURL, clickElement, takeScreenshot\n",
    "from PIL import Image\n",
    "\n",
    "import networkx as nx\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "import requests\n",
    "import io\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllClickables(driver):\n",
    "    elements = []\n",
    "\n",
    "    elements_a = driver.find_elements(By.TAG_NAME, 'a')\n",
    "    for element in elements_a:\n",
    "        if element.is_displayed() and element.is_enabled() and element.rect.__len__() != 0:  # excluding all the hidden links\n",
    "            # print(element.get_property('attributes')[0].items(), \"\\n\")\n",
    "\n",
    "            data = {}\n",
    "            data['x'] = element.rect['x']\n",
    "            data['y'] = element.rect['y']\n",
    "            data['width'] = element.rect['width']\n",
    "            data['height'] = element.rect['height']\n",
    "            data['outer_html'] = base64Encode(bytes(element.get_attribute('outerHTML'), \"utf-8\")) \n",
    "            data['href'] = element.get_dom_attribute('href') if element.get_dom_attribute('href') else 'None'\n",
    "            data['href_full'] = element.get_attribute('href') if element.get_attribute('href') else 'None'\n",
    "            data['class'] = element.get_attribute('class')\n",
    "\n",
    "            texts = list(itertools.chain(*[text.text.split('\\n') for text in element.find_elements(By.XPATH, '..//div')]))\n",
    "            texts.append(element.text)\n",
    "            data['text'] = list(set([text for text in texts if len(text) > 0] ))\n",
    "\n",
    "            # getting closer image(s) if available\n",
    "            imgs=element.find_elements(By.XPATH, \".//img\")\n",
    "            if len(imgs) > 0:\n",
    "                for i, img in enumerate(imgs):\n",
    "                    data['img_'+str(i)] = imgURL2B64(img.get_attribute('src'))\n",
    "\n",
    "            elements.append(data)\n",
    "    return elements\n",
    "\n",
    "# to get the URL of current page on iframe\n",
    "def getCurrntURLIFrame(driver):\n",
    "    url = driver.execute_script('return location.href')\n",
    "    url = url.replace('http://localhost:4200', \"\")\n",
    "    return url\n",
    "\n",
    "# download image from URL and convert to base64\n",
    "def imgURL2B64(imgURL):\n",
    "    # downloading image\n",
    "    img_data = requests.get(imgURL).content\n",
    "    # encoding\n",
    "    return base64Encode(img_data)\n",
    "\n",
    "# convert bytes string to b64 \n",
    "def base64Encode(data):\n",
    "    return base64.b64encode(data).decode(\"utf-8\")\n",
    "\n",
    "# show image from base64\n",
    "def imgFromB64(imgb64):\n",
    "    # reconstructing the image by decoding\n",
    "    img64dec = base64.b64decode(imgb64)\n",
    "    Image.open(io.BytesIO(img64dec)).show()\n",
    "\n",
    "# format data to store\n",
    "def formatData(chosenLink):\n",
    "    data = {}\n",
    "    data['y'] = chosenLink['y']\n",
    "    data['y_offset'] = 0\n",
    "    data['x'] = chosenLink['x']\n",
    "    data['x_offset'] = 0\n",
    "    \n",
    "    if chosenLink['y'] + chosenLink['height'] > 865:\n",
    "        data['y_offset'] = chosenLink['y'] + chosenLink['height'] - 865\n",
    "        data['y'] = chosenLink['y'] - data['y_offset']\n",
    "\n",
    "    if chosenLink['x'] + chosenLink['width'] > 812:\n",
    "        data['x_offset'] = chosenLink['x'] + chosenLink['width'] - 812\n",
    "        data['x'] = chosenLink['x'] - data['x_offset']\n",
    "\n",
    "    # new attributes to the chosen link\n",
    "    chosenLink['type'] = \"click\"\n",
    "    chosenLink['y'] = data['y']\n",
    "    chosenLink['y_offset'] = data['y_offset']\n",
    "    chosenLink['x'] = data['x']\n",
    "    chosenLink['x_offset'] = data['x_offset']\n",
    "    return chosenLink\n",
    "\n",
    "# retrieves all the text on the page\n",
    "def getTextOnPage(driver):\n",
    "    divs = driver.find_elements(By.TAG_NAME, 'div')\n",
    "    return list(set(list(itertools.chain(*[[divText for divText in divs[i].text.split('\\n') if len(divText) > 0] for i in range(len(divs))]))))\n",
    "\n",
    "def formatDataForPlayer(inputJson):\n",
    "    data = {}\n",
    "    data['url'] = inputJson['url']\n",
    "\n",
    "    actions = [];\n",
    "    for in_action in inputJson['actions'][:-1]:\n",
    "        action = {}\n",
    "        action['type'] = in_action['clicked']['type']\n",
    "        action['x'] = in_action['clicked']['x']\n",
    "        action['y'] = in_action['clicked']['y']\n",
    "        action['height'] = in_action['clicked']['height']\n",
    "        action['width'] = in_action['clicked']['width']\n",
    "        action['x_offset'] = in_action['clicked']['x_offset']\n",
    "        action['y_offset'] = in_action['clicked']['y_offset']\n",
    "        action['href'] = in_action['clicked']['href']\n",
    "        action['href_full'] = in_action['clicked']['href_full']\n",
    "        action['outer_html'] = in_action['clicked']['outer_html']\n",
    "\n",
    "        actions.append(action)\n",
    "        \n",
    "    data['actions'] = actions\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks one against a list\n",
    "def isSimilar(query, reference, score):\n",
    "    points = 0\n",
    "    # relative url match\n",
    "    if(query[0]) == reference[0]:\n",
    "        points += 1\n",
    "\n",
    "    # absolute url match\n",
    "    if(query[1]) == reference[1]:\n",
    "        points += 1\n",
    "  \n",
    "    # class match  \n",
    "    if(query[2]) == reference[2]:\n",
    "        points += 1 \n",
    "\n",
    "    return points >= score\n",
    "\n",
    "# check one url\n",
    "def checkIfIn(query, urlList, score=2):\n",
    "    for url in urlList:\n",
    "        if isSimilar(query, url, score):\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [\n",
    "     ('premium-collection/index.html', 'theevolutionstore.com/premium-collection/index.html', 'hasSub sf-with-ul'),\n",
    "     ('preserved-mounted-specimens/index.html', 'theevolutionstore.com/preserved-mounted-specimens/index.html', 'hasSub sf-with-ul'),\n",
    "     ('skulls-skeletons-anatomy-more/index.html', 'theevolutionstore.com/skulls-skeletons-anatomy-more/index.html', 'hasSub sf-with-ul'),\n",
    "     ('meteorites-fossils-minerals/index.html', 'theevolutionstore.com/meteorites-fossils-minerals/index.html', 'hasSub sf-with-ul'),\n",
    "     ('home-decor-art/index.html', 'theevolutionstore.com/home-decor-art/index.html', 'hasSub sf-with-ul'),\n",
    "     ('jewelry-clothing-accessories/index.html', 'theevolutionstore.com/jewelry-clothing-accessories/index.html', 'hasSub sf-with-ul'),\n",
    "     ('puzzles-toys-edibles/index.html', 'theevolutionstore.com/puzzles-toys-edibles/index.html', 'hasSub sf-with-ul'),\n",
    "]\n",
    "\n",
    "l2 = [\n",
    "     # premium collection\n",
    "     ('entomology/index.html', 'theevolutionstore.com/premium-collection/entomology/index.html', ''),\n",
    "     ('taxidermy-specimens/index.html', 'theevolutionstore.com/premium-collection/taxidermy-specimens/index.html', ''),\n",
    "     ('fossils/index.html', 'theevolutionstore.com/premium-collection/fossils/index.html', ''),\n",
    "     ('home-decor/index.html', 'theevolutionstore.com/premium-collection/home-decor/index.html', ''),\n",
    "     ('minerals-meteorites/index.html', 'theevolutionstore.com/premium-collection/minerals-meteorites/index.html', ''),\n",
    "\n",
    "     #  preserved and mounted\n",
    "     ('preserved-specimens/index.html', 'theevolutionstore.com/preserved-mounted-specimens/preserved-specimens/index.html', ''),\n",
    "     ('sea-life/index.html', 'theevolutionstore.com/preserved-mounted-specimens/sea-life/index.html', ''),\n",
    "     ('specimens-in-resin/index.html', 'theevolutionstore.com/preserved-mounted-specimens/specimens-in-resin/index.html', ''),\n",
    "     ('taxidermy/index.html', 'theevolutionstore.com/preserved-mounted-specimens/taxidermy/index.html', ''),\n",
    "     ('framed-unframed-insects/index.html', 'theevolutionstore.com/preserved-mounted-specimens/framed-unframed-insects/index.html', ''),\n",
    "\n",
    "     # skills, skeleton, anatomy and more\n",
    "     ('replica-human-bone/index.html', 'theevolutionstore.com/skulls-skeletons-anatomy-more/replica-human-bone/index.html', ''),\n",
    "     ('anatomical-models/index.html', 'theevolutionstore.com/skulls-skeletons-anatomy-more/anatomical-models/index.html', ''),\n",
    "     ('natural-animal-bone/index.html', 'theevolutionstore.com/skulls-skeletons-anatomy-more/natural-animal-bone/index.html', ''),\n",
    "     ('replica-extinct-animal-bone/index.html', 'theevolutionstore.com/skulls-skeletons-anatomy-more/replica-extinct-animal-bone/index.html', ''),\n",
    "\n",
    "     # meteorites, fossils and minerals\n",
    "     ('meteorites/index.html', 'theevolutionstore.com/meteorites-fossils-minerals/meteorites/index.html', ''),\n",
    "     ('minerals/index.html', 'theevolutionstore.com/meteorites-fossils-minerals/minerals/index.html', ''),\n",
    "     ('fossils/index.html', 'theevolutionstore.com/meteorites-fossils-minerals/fossils/index.html', ''),\n",
    "\n",
    "     # home decor\n",
    "     ('desk-study/globes/index.html', 'theevolutionstore.com/home-decor-art/desk-study/globes/index.html', ''),\n",
    "     ('../preserved-mounted-specimens/domes/index.html', 'theevolutionstore.com/preserved-mounted-specimens/domes/index.html', ''),\n",
    "     ('skull-decor/index.html', 'theevolutionstore.com/home-decor-art/skull-decor/index.html', ''),\n",
    "     ('tabletop-bath/index.html', 'theevolutionstore.com/home-decor-art/tabletop-bath/index.html', ''),\n",
    "     ('desk-study/index.html', 'theevolutionstore.com/home-decor-art/desk-study/index.html', ''),\n",
    "     ('posters-prints/index.html', 'theevolutionstore.com/home-decor-art/posters-prints/index.html', ''),\n",
    "     ('rugs/index.html', 'theevolutionstore.com/home-decor-art/rugs/index.html', ''),\n",
    "     ('art-artifacts/index.html', 'theevolutionstore.com/home-decor-art/art-artifacts/index.html', ''),\n",
    "\n",
    "     # jewellery, clothing\n",
    "     ('jewelry/index.html', 'theevolutionstore.com/jewelry-clothing-accessories/jewelry/index.html', ''),\n",
    "     ('clothing-accessories/index.html', 'theevolutionstore.com/jewelry-clothing-accessories/clothing-accessories/index.html', ''),\n",
    "\n",
    "     # puzzles, toys\n",
    "     ('puzzles-models/index.html', 'theevolutionstore.com/puzzles-toys-edibles/puzzles-models/index.html', ''),\n",
    "     ('candies-snacks/index.html', 'theevolutionstore.com/puzzles-toys-edibles/candies-snacks/index.html', ''),\n",
    "     ('other-toys/index.html', 'theevolutionstore.com/puzzles-toys-edibles/other-toys/index.html', ''),\n",
    "]\n",
    "\n",
    "l3 = [\n",
    "     \n",
    "]\n",
    "\n",
    "hardToEliminate = [\n",
    "\n",
    "]\n",
    "\n",
    "eliminate = [\n",
    "     ('about-us/index.html', 'theevolutionstore.com/about-us/index.html', ''),\n",
    "     ('contact-us/index.html', 'theevolutionstore.com/contact-us/index.html', ''),\n",
    "     ('international-shipping/index.html', 'theevolutionstore.com/international-shipping/index.html', ''),\n",
    "     ('rentals/index.html', 'theevolutionstore.com/rentals/index.html', ''),\n",
    "     ('tel:212.343.1114', 'tel:212.343.1114', ''),\n",
    "     ('logine568.html', 'theevolutionstore.com/logine568.html', ''),\n",
    "     ('login.html', 'theevolutionstore.com/login.html', 'Signin'),\n",
    "     ('login830b.html', 'theevolutionstore.com/login830b.html', ''),\n",
    "     ('cart.html', 'theevolutionstore.com/cart.html', ''),\n",
    "     ('index.html', 'theevolutionstore.com/index.html', ''),\n",
    "     ('anatomical-snap-together-kit-heart-original/index.html', 'theevolutionstore.com/anatomical-snap-together-kit-heart-original/index.html', ''),\n",
    "     ('None', 'None', ''),\n",
    "     ('None', 'None', ''),\n",
    "     ('None', 'None', ''),\n",
    "     ('None', 'None', 'flex-active'),\n",
    "     ('None', 'None', ''),\n",
    "     ('preserved-mounted-specimens/framed-unframed-insects/index.html', 'theevolutionstore.com/preserved-mounted-specimens/framed-unframed-insects/index.html', ''),\n",
    "     ('home-decor-art/posters-prints/seba-prints/index.html', 'theevolutionstore.com/home-decor-art/posters-prints/seba-prints/index.html', ''),\n",
    "     ('#Tablist1', 'theevolutionstore.com/index.html#Tablist1', ''),\n",
    "     ('#Tablist2', 'theevolutionstore.com/index.html#Tablist2', ''),\n",
    "]\n",
    "\n",
    "pageBottomURLs = [\n",
    "     ('https://us13.campaign-archive.com/?u=764e88655f97f7c006065cd5a&id=bb1dab1df4', 'https://us13.campaign-archive.com/?u=764e88655f97f7c006065cd5a&id=bb1dab1df4', ''),\n",
    "     ('https://us13.campaign-archive.com/?u=764e88655f97f7c006065cd5a&id=0b9a1e760f', 'https://us13.campaign-archive.com/?u=764e88655f97f7c006065cd5a&id=0b9a1e760f', ''),\n",
    "     ('https://www.facebook.com/theevolutionstore', 'https://www.facebook.com/theevolutionstore', ''),\n",
    "     ('http://instagram.com/theevolutionstore', 'http://instagram.com/theevolutionstore', 'icon-social icon-social-theme icon-instagram'),\n",
    "     ('https://www.facebook.com/theevolutionstore', 'https://www.facebook.com/theevolutionstore', 'icon-social icon-social-theme icon-facebook'),\n",
    "     ('https://www.tiktok.com/@theevolutionstore', 'https://www.tiktok.com/@theevolutionstore', 'icon-social icon-social-theme icon-tumblr'),\n",
    "     ('https://www.youtube.com/channel/UCfaEOsX8SRegQH9KICuNepQ', 'https://www.youtube.com/channel/UCfaEOsX8SRegQH9KICuNepQ', 'icon-social icon-social-theme icon-youtube'),\n",
    "     ('https://twitter.com/theevolutionnyc', 'https://twitter.com/theevolutionnyc', 'icon-social icon-social-theme icon-twitter'),\n",
    "     ('https://www.pinterest.com/evolutionstore/', 'https://www.pinterest.com/evolutionstore/', 'icon-social icon-social-theme icon-pinterest'),\n",
    "     ('https://www.google.com/maps/place/687+Broadway,+New+York,+NY+10012/@40.7290403,-73.9946526,17.47z/data=!4m5!3m4!1s0x89c2599aa0dbbc01:0x40850771c5f6edb!8m2!3d40.7281384!4d-73.9947995', 'https://www.google.com/maps/place/687+Broadway,+New+York,+NY+10012/@40.7290403,-73.9946526,17.47z/data=!4m5!3m4!1s0x89c2599aa0dbbc01:0x40850771c5f6edb!8m2!3d40.7281384!4d-73.9947995', ''),\n",
    "     ('tel:212.343.1114', 'tel:212.343.1114', ''),\n",
    "     ('mailto:Info@TheEvolutionStore.com', 'mailto:Info@TheEvolutionStore.com', '')\n",
    "]\n",
    "\n",
    "forceClick = [\n",
    "\n",
    "]\n",
    "\n",
    "def l3Handle(l2):\n",
    "     if (\"womens\" in l2['href']):\n",
    "          return l3[:7]\n",
    "     elif(\"kids\" in l2['href']):\n",
    "          return l3[7:12]\n",
    "     elif(\"mens\" in l2['href']):\n",
    "          return l3[12:]\n",
    "\n",
    "def matchSimilarLinks(candidate_clickables):\n",
    "     f_list = []\n",
    "     # add text of second one to the first one\n",
    "     for i in range(len(candidate_clickables)):\n",
    "          if candidate_clickables[i]['class'] == 'pname':\n",
    "               candidate_clickables[i-1]['text'] = candidate_clickables[i]['text']\n",
    "               f_list.append(candidate_clickables[i-1])\n",
    "          \n",
    "          # also adding links to navigate between pages\n",
    "          if \"page=\" in candidate_clickables[i]['href']:\n",
    "               f_list.append(candidate_clickables[i])\n",
    "     return f_list\n",
    "     \n",
    "def checkVisitedTargets(candidate_clickables, trackTargetLinks):\n",
    "     for target in trackTargetLinks:\n",
    "          candidate_clickables = [clickable for clickable in candidate_clickables if not (clickable['x'] == target['x'] and clickable['y'] == target['y'])]\n",
    "     return candidate_clickables\n",
    "\n",
    "def checkIfTargetPage(candidate_clickables):\n",
    "     score = 0\n",
    "     clickable_list = []\n",
    "     for clickable in candidate_clickables:\n",
    "          if any(x in clickable['text'] for x in [\"Description\", \"Details\", \"Reviews\"]) and clickable['href'] == \"#\":\n",
    "               score += 1\n",
    "               clickable_list.append(clickable)\n",
    "     return score >= 2, clickable_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_1675220935_ES_5 ['puzzles-toys-edibles/index.html', 'index36c2.html?sort=featured&page=3', '../metal-scorpion-kit/index.html', '#', '#']\n",
      "R_1675221022_ES_5 ['puzzles-toys-edibles/index.html', 'indexf1d4.html?sort=featured&page=2', 'index1bb6.html?sort=featured&page=1', '../tiny-stegosaurus/index.html', '#']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 134\u001b[0m\n\u001b[1;32m    132\u001b[0m                 selected_products \u001b[39m=\u001b[39m []\n\u001b[1;32m    133\u001b[0m                 no_products \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 134\u001b[0m collectData()\n",
      "Cell \u001b[0;32mIn [7], line 26\u001b[0m, in \u001b[0;36mcollectData\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m step\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[39mwhile\u001b[39;00m step \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m stepitr: \u001b[39m# going through steps in a single data point, adding one more to include the details of the last page\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     scrollToTheBottom(driver)\n\u001b[1;32m     27\u001b[0m     candidate_clickables \u001b[39m=\u001b[39m getAllClickables(driver)\n\u001b[1;32m     28\u001b[0m     forRecords \u001b[39m=\u001b[39m candidate_clickables\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/Volumes/ddrive/WVLN/WVLN_Simulator/sim_com/SimulatorCommunicator.py:79\u001b[0m, in \u001b[0;36mscrollToTheBottom\u001b[0;34m(driver)\u001b[0m\n\u001b[1;32m     77\u001b[0m scrollTo(driver, \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdocument.body.scrollHeight\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[39m# to come back to the top\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m scrollTo(driver, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/Volumes/ddrive/WVLN/WVLN_Simulator/sim_com/SimulatorCommunicator.py:72\u001b[0m, in \u001b[0;36mscrollTo\u001b[0;34m(driver, x, y)\u001b[0m\n\u001b[1;32m     70\u001b[0m last_height \u001b[39m=\u001b[39m new_height\n\u001b[1;32m     71\u001b[0m driver\u001b[39m.\u001b[39mexecute_script(\u001b[39m\"\u001b[39m\u001b[39mwindow.scrollTo(\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(x, y))\n\u001b[0;32m---> 72\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     73\u001b[0m new_height \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mexecute_script(\u001b[39m\"\u001b[39m\u001b[39mreturn document.body.scrollHeight\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start from menu\n",
    "base = \"http://localhost:4200/assets/crawled/es/\"\n",
    "\n",
    "def collectData():\n",
    "    stepitr = 3\n",
    "    dpoint=1\n",
    "    no_products = 0 # flag to identify if all the products are visited\n",
    "    selected_products = []\n",
    "    while dpoint <= 85: # no. of recordings needed from one seq. count\n",
    "        driver = setup(9228, 'assets/crawled/es/index.html', True)\n",
    "        switchToIframe(driver)\n",
    "\n",
    "        menuState = 'non'\n",
    "        visited = [] # to store visited links in one sequence\n",
    "        data = {} # to collect data in one sequence\n",
    "        data['url'] = \"assets/crawled/es/index.html\"\n",
    "        actions = [] # to store clicks\n",
    "        nextTrack = False\n",
    "        nextActiveinDataPoint = False\n",
    "\n",
    "        trackTargetLinks = []\n",
    "        try:\n",
    "            step=0\n",
    "            while step <= stepitr: # going through steps in a single data point, adding one more to include the details of the last page\n",
    "\n",
    "                scrollToTheBottom(driver)\n",
    "                candidate_clickables = getAllClickables(driver)\n",
    "                forRecords = candidate_clickables.copy()\n",
    "\n",
    "                # remove everytime\n",
    "                candidate_clickables = [clickable for clickable in candidate_clickables if not checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), eliminate+pageBottomURLs+hardToEliminate, 2)]\n",
    "\n",
    "                # eliminating already visited ones\n",
    "                candidate_clickables = [clickable for clickable in candidate_clickables if not checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), visited, 2)]\n",
    "\n",
    "                # adding constraints to click a button\n",
    "                if step == 0:\n",
    "                    candidate_clickables = [clickable for clickable in candidate_clickables if checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), l1[6:7], 2)]\n",
    "                else:\n",
    "                    candidate_clickables = [clickable for clickable in candidate_clickables if not checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), l1, 2)]\n",
    "\n",
    "                move2lvl2 = random.randint(1,10) > 5\n",
    "                if menuState == 'l1' and move2lvl2:\n",
    "                    candidate_clickables = [clickable for clickable in candidate_clickables if checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), l2, 2)]\n",
    "                if (menuState == 'l1' and not move2lvl2) or menuState == 'l2' or nextTrack:\n",
    "                    candidate_clickables = matchSimilarLinks(candidate_clickables.copy())\n",
    "\n",
    "                # identifying if in a target page\n",
    "                isTargetPage, lst = checkIfTargetPage(candidate_clickables.copy())\n",
    "                if isTargetPage:                    \n",
    "                    # removing none links\n",
    "                    candidate_clickables = checkVisitedTargets(lst, trackTargetLinks)\n",
    "                    # maxItr =  4 if nextActiveinDataPoint else 3\n",
    "                    step = step-1 if len(candidate_clickables) > 2 and len(actions) <= 3 else step\n",
    "                \n",
    "                # to force to go to next page\n",
    "                if ((menuState=='l1' and not move2lvl2) or (menuState=='l2')) and (not nextActiveinDataPoint and any(\"page=\" in clickable[\"href_full\"] for clickable in candidate_clickables)):\n",
    "                    candidate_clickables = [clickable for clickable in candidate_clickables if \"page=\" in clickable['href_full']]\n",
    "\n",
    "                # if still not in a target page\n",
    "                if step >= 3 and len(actions) <= 6 and not isTargetPage:\n",
    "                    candidate_clickables = [clickable for clickable in candidate_clickables if not \"page=\" in clickable['href_full']]\n",
    "                    step-=1\n",
    "\n",
    "                # choosing a clickable randomly\n",
    "                if step < stepitr:\n",
    "                    # removing already visited products\n",
    "                    if len(actions) > 0 and len(selected_products)>0 and not isTargetPage:\n",
    "                        candidate_clickables = [clickable for clickable in candidate_clickables if clickable['href_full'] not in selected_products]\n",
    "                        no_products = no_products+1 if len(candidate_clickables)==0 else no_products # to identify if all the products were visited\n",
    "\n",
    "                    random.seed()\n",
    "                    random.shuffle(candidate_clickables)\n",
    "                    chosenLink = random.choice(candidate_clickables)\n",
    "\n",
    "                    if step >= 1 and not checkIfIn((chosenLink['href'], chosenLink['href_full'].replace(base,\"\"), chosenLink['class']), l1+l2) and not isTargetPage and not \"page=\" in chosenLink['href']:\n",
    "                        selected_products.append(chosenLink['href_full'])\n",
    "\n",
    "                    # assigning the menu state\n",
    "                    if checkIfIn((chosenLink['href'], chosenLink['href_full'].replace(base,\"\"), chosenLink['class']), l1):\n",
    "                        menuState = 'l1'\n",
    "                    elif checkIfIn((chosenLink['href'], chosenLink['href_full'].replace(base,\"\"), chosenLink['class']), l2):\n",
    "                        menuState = 'l2'\n",
    "                    else:\n",
    "                        menuState = 'non'\n",
    "                    \n",
    "                    # adding to the visited list\n",
    "                    if isTargetPage:\n",
    "                        trackTargetLinks.append({'x':chosenLink['x'], 'y': chosenLink['y']})\n",
    "                    else:\n",
    "                        visited.append((chosenLink['href'], chosenLink['href_full'].replace(base,\"\"), chosenLink['class']))\n",
    "                    \n",
    "                    if 'page=' in chosenLink['href_full']:\n",
    "                        nextTrack = True\n",
    "                        nextActiveinDataPoint = True\n",
    "                        step = step-1 if len(actions) <= 5 else step\n",
    "                    else:\n",
    "                        nextTrack = False\n",
    "\n",
    "                actions.append({\n",
    "                    'clicked': formatData(chosenLink.copy()) if step < stepitr else None,\n",
    "                    'candidates': [formatData(clickable.copy()) for clickable in forRecords],\n",
    "                    'screenshot': takeScreenshot(driver),\n",
    "                    'full_url': getCurrntURLIFrame(driver),\n",
    "                    'text': getTextOnPage(driver)\n",
    "                    })\n",
    "\n",
    "                # print(chosenLink['href_full'])\n",
    "                if step < stepitr:\n",
    "                    clickElement(driver, chosenLink['x'], chosenLink['y'])\n",
    "                step += 1\n",
    "\n",
    "            data['actions'] = actions\n",
    "            data['nClicks'] = len(actions)-1\n",
    "\n",
    "            # saving to a json file for ML\n",
    "            fname = 'R_' + str(int(time.time())) + '_ES_' + str(len(actions)-1)\n",
    "            with open('data/' + fname + '.json', 'w') as f:\n",
    "                json.dump(data, f)\n",
    "\n",
    "            # # saving to a json file for player\n",
    "            with open('data_player/' + fname + '.json', 'w') as f:\n",
    "                json.dump(formatDataForPlayer(data), f)\n",
    "            \n",
    "            dpoint+=1 # increasing the iteration number\n",
    "            print(fname, [action['clicked']['href'] for action in actions[:-1]])\n",
    "            \n",
    "            # break\n",
    "        except Exception as e:\n",
    "            print(\"error\", e)\n",
    "            if no_products >= 3:\n",
    "                selected_products = []\n",
    "                no_products = 0\n",
    "collectData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "driver = setup(9222, 'assets/crawled/es/index.html', False)\n",
    "switchToIframe(driver)\n",
    "# elements_a = driver.find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "candidate_clickables = getAllClickables(driver)\n",
    "# candidate_clickables = [(clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']) for clickable in getAllClickables(driver)]\n",
    "candidate_clickables = [(clickable['text'], clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']) for clickable in candidate_clickables if not checkIfIn((clickable['href'], clickable['href_full'].replace(base,\"\"), clickable['class']), eliminate+pageBottomURLs+l1, 2)]\n",
    "\n",
    "\n",
    "# data = {\n",
    "#     'href':'assets/crawled/sna/www.sarahandabraham.com/index.html',\n",
    "#     'href_full':'assets/crawled/sna/www.sarahandabraham.com/index.html',\n",
    "#     'x': 0,\n",
    "#     'y': 0}\n",
    "candidate_clickables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To show an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load an image\n",
    "def imgFromB64(imgb64):\n",
    "    # reconstructing the image by decoding\n",
    "    img64dec = base64.b64decode(imgb64)\n",
    "    Image.open(io.BytesIO(img64dec)).show()\n",
    "\n",
    "with open('data/R_1674999707_ES_6.json', 'r') as f:\n",
    "    imgFromB64(json.load(f)['actions'][1]['screenshot'])\n",
    "    # imgFromB64(json.load(f)['actions'][0]['candidates'][31]['img_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectData(n_data):\n",
    "    driver = setup()\n",
    "    switchToIframe(driver)\n",
    "\n",
    "    for i in range(n_data):\n",
    "        # scrollToTheBottom(driver)\n",
    "        # clickables = getAllClickables(driver)\n",
    "        # chosenLink = random.choice(clickables[10:])\n",
    "        # print(chosenLink)\n",
    "\n",
    "        clickElement(driver, 414, 3000)\n",
    "        break\n",
    "\n",
    "        \n",
    "\n",
    "# collectData(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To delete paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Good</th>\n",
       "      <th>Bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1671539062_3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1671539104_3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1671539149_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1671539201_3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1671539251_3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           File  Good  Bad\n",
       "0  1671539062_3   1.0  NaN\n",
       "1  1671539104_3   1.0  NaN\n",
       "2  1671539149_3   NaN  1.0\n",
       "3  1671539201_3   1.0  NaN\n",
       "4  1671539251_3   1.0  NaN"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback = pd.read_csv(\"Data Quality Checker.csv\")\n",
    "feedback.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting bad ones\n",
    "feedbackBad = feedback.copy(deep=True)\n",
    "feedbackBad.File = feedbackBad.File.map(lambda x: 'R_'+ x + '.json')\n",
    "bad = feedbackBad.loc[feedbackBad.Bad == 1].File.tolist()\n",
    "\n",
    "videos = 'data_player/'\n",
    "mlData = 'data/'\n",
    "for (dirpath, dirnames, filenames) in os.walk(mlData):\n",
    "    for filename in filenames:\n",
    "        if filename in bad:\n",
    "            os.remove(dirpath + filename)\n",
    "            # print(dirpath, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding good ones to a csv\n",
    "feedback.File = feedback.File.map(lambda x: 'R_'+ x)\n",
    "good = feedback.loc[feedback.Good == 1].File.tolist()\n",
    "pd.DataFrame({'token':good}).to_csv('tokens.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('wvln')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "5262f72f792da6885bb3d262717436bebfd49eeb6fd743e7744cb17ed52f3a82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
